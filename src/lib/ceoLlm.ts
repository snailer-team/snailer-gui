/**
 * CEO LLM Integration for Auto-Cycle
 *
 * Builds observe context, generates CEO prompts, and parses JSON output.
 */

import type { CeoLlmOutput, TopLeverageItem, ElonXState, Broadcast, CycleRun, ElonAgentState } from './store'
import type { PlanTree, PlanNode } from './elonPlan'
import type { Evidence } from './elonEvidence'

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Observe Context Building
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

function summarizePlanTree(planTree: PlanTree | null): string {
  if (!planTree || !planTree.root) {
    return 'No active plan tree.'
  }

  const countByStatus = (node: PlanNode, status: PlanNode['status']): number => {
    let count = node.status === status ? 1 : 0
    for (const child of node.children) {
      count += countByStatus(child, status)
    }
    return count
  }

  const findBottlenecks = (node: PlanNode): string[] => {
    const bottlenecks: string[] = []
    if (node.status === 'blocked' || node.status === 'failed') {
      bottlenecks.push(`${node.title} (${node.status})`)
    }
    for (const child of node.children) {
      bottlenecks.push(...findBottlenecks(child))
    }
    return bottlenecks
  }

  const running = countByStatus(planTree.root, 'running')
  const completed = countByStatus(planTree.root, 'completed')
  const blocked = countByStatus(planTree.root, 'blocked')
  const failed = countByStatus(planTree.root, 'failed')
  const pending = countByStatus(planTree.root, 'pending')
  const bottlenecks = findBottlenecks(planTree.root).slice(0, 5)

  return `Plan: "${planTree.problem}"
Status: ${planTree.status}
Progress: ${completed} completed, ${running} running, ${pending} pending, ${blocked} blocked, ${failed} failed
${bottlenecks.length > 0 ? `Bottlenecks: ${bottlenecks.join(', ')}` : 'No bottlenecks.'}`
}

function summarizeEvidences(evidences: Evidence[]): string {
  if (evidences.length === 0) {
    return 'No recent evidence.'
  }

  const recent = evidences.slice(0, 10)
  const summary = recent.map((e) => {
    const verdict = e.verdict === 'pass' ? 'âœ“' : e.verdict === 'fail' ? 'âœ—' : 'âš '
    return `- ${verdict} [${e.type}] ${e.title}: ${e.summary}`
  })

  return `Recent Evidence (${evidences.length} total):
${summary.join('\n')}`
}

function summarizeAgentStatuses(statuses: Record<string, ElonAgentState>): string {
  const agents = Object.values(statuses)
  if (agents.length === 0) {
    return 'No active agents.'
  }

  const summary = agents.slice(0, 10).map((a) => {
    const task = a.currentTask ? ` | task: ${a.currentTask.slice(0, 80)}` : ''
    const output = a.lastOutput ? ` | lastOutput: ${a.lastOutput.slice(0, 200)}` : ''
    const quality = a.lastOutputQuality ? ` | quality: ${a.lastOutputQuality}` : ''
    return `- ${a.id}: ${a.status}${quality}${task}${output}`
  })

  return `Agent Status (${agents.length} agents):
${summary.join('\n')}`
}

function summarizeCycleHistory(cycleRuns: CycleRun[]): string {
  const recent = cycleRuns.filter((r) => r.status === 'completed').slice(0, 3)
  if (recent.length === 0) {
    return 'No previous cycles.'
  }

  const lines = recent.map((r) => {
    const summary = r.llmOutput?.cycleSummary ?? '(no summary)'
    const tasks = r.llmOutput?.topLeverage?.map((l) => `${l.assignee}: ${l.title}`).join('; ') ?? ''
    return `- Cycle ${r.id.slice(0, 8)} (${Math.round((Date.now() - (r.endedAt ?? r.startedAt)) / 60000)}m ago): ${summary}${tasks ? `\n  Tasks: ${tasks}` : ''}`
  })

  return `Recent Cycle History (${cycleRuns.length} total, showing last ${recent.length}):
${lines.join('\n')}`
}

function summarizeActiveBroadcasts(broadcasts: Broadcast[]): string {
  const active = broadcasts.filter((b) => b.status === 'active')
  if (active.length === 0) {
    return 'No active broadcasts.'
  }

  const lines = active.map((b) => {
    return `- To [${b.toAgentIds.join(', ')}]: ${b.message.slice(0, 120)}`
  })

  return `Currently Active Broadcasts (${active.length}):
${lines.join('\n')}`
}

export function buildObserveContext(elonX: ElonXState): string {
  const planSummary = summarizePlanTree(elonX.planTree)
  const evidenceSummary = summarizeEvidences(elonX.evidences)
  const agentSummary = summarizeAgentStatuses(elonX.agentStatuses)
  const cycleSummary = summarizeCycleHistory(elonX.cycleRuns)
  const broadcastSummary = summarizeActiveBroadcasts(elonX.broadcasts)

  return `## Current State (Observe)

${planSummary}

${evidenceSummary}

${agentSummary}

${cycleSummary}

${broadcastSummary}

IMPORTANT: Do NOT repeat the same directives from previous cycles. Review what agents already did (lastOutput) and active broadcasts above. Build on completed work, assign NEW next-step tasks, or pivot if previous approach was insufficient.`
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// CEO Prompt Generation
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export const CEO_SYSTEM_PROMPT = `You are the CEO of an AI-powered software company operating in ElonX HARD mode.

Your role:
1. OBSERVE: Analyze current state (plan tree, evidence, agent statuses)
2. PLAN: Identify top 1-3 leverage points that will move the needle most
3. ACT: Create clear, actionable broadcasts for each agent
4. EVALUATE: Consider risks and acceptance criteria

Principles:
- First Principles thinking: Challenge assumptions
- High Leverage: Focus on what matters most
- Short & Sharp: No fluff, direct communication
- Revenue-first: Prioritize actions that impact business
- Daily iteration: Ship fast, iterate faster
- Macro Judge (Elon role): Agents show you demos/results. Say "good" to accelerate or "wrong" to trigger war room surge
- Delete First: Kill bad ideas/code immediately. No dead features
- Bottom-up: Trust agents to self-start. Only intervene when direction is wrong

You MUST respond with valid JSON matching this exact schema:
{
  "cycleSummary": "1-2 sentence summary of current situation",
  "topLeverage": [
    {
      "title": "short task title",
      "assignee": "pm|swe-2|swe-3|ai-ml|qa",
      "why": "1 line explaining leverage/impact",
      "risk": "low|medium|high",
      "evidenceIds": [],
      "acceptance": ["criterion 1", "criterion 2"]
    }
  ],
  "broadcasts": [
    {
      "to": "agent-id",
      "message": "1-3 line directive",
      "expiresMins": 60
    }
  ],
  "needsExternalData": false
}

Available agents: pm, swe-2, swe-3, ai-ml, qa

Agent Roles:
- pm: Product management, feature specs, prioritization, user research
- swe-2, swe-3: Software engineering, code implementation, PRs, bug fixes
- ai-ml: AI/ML research, model evaluation, data pipeline, experiments
- qa: Quality assurance, test automation, bug hunting, CI/CD quality gates (uses GPT-5.2)

Quality Enforcement Rules:
- If an SWE agent has quality "text_only", they failed to produce code. Re-assign with explicit instruction: "You MUST include codeDiff in write_code actions."
- If an SWE agent has quality "code_verified", they produced real code. Build on their work.
- If a PM agent has quality "actionable", their analysis was strong. Reference their findings.
- Assign QA agent to review SWE PRs, run test suites, and validate quality gates before merge.
- Assign AI-ML agent for model performance analysis, experiment design, and data pipeline work.
- Check pending GitHub approval requests in broadcasts and approve/reject as needed.

Only output valid JSON. No markdown, no explanation.`

export function buildCeoPrompt(observeContext: string): string {
  return `${CEO_SYSTEM_PROMPT}

${observeContext}

Based on the current state above, identify the top leverage opportunities and create broadcasts for the agents.
Respond with JSON only.`
}

/**
 * Build separate system/user messages for xAI API direct call.
 */
export function buildCeoMessages(observeContext: string): { systemPrompt: string; userPrompt: string } {
  return {
    systemPrompt: CEO_SYSTEM_PROMPT,
    userPrompt: `${observeContext}

Based on the current state above, identify the top leverage opportunities and create broadcasts for the agents.
Respond with JSON only.`,
  }
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// JSON Output Parsing
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export function parseCeoLlmOutput(rawOutput: string): CeoLlmOutput {
  // Try to extract JSON from the response
  let jsonStr = rawOutput.trim()

  // Handle markdown code blocks
  const jsonMatch = rawOutput.match(/```(?:json)?\s*([\s\S]*?)```/)
  if (jsonMatch) {
    jsonStr = jsonMatch[1].trim()
  }

  // Parse JSON
  const parsed = JSON.parse(jsonStr)

  // Validate required fields
  if (typeof parsed.cycleSummary !== 'string') {
    throw new Error('Missing cycleSummary')
  }
  if (!Array.isArray(parsed.topLeverage)) {
    throw new Error('Missing topLeverage array')
  }
  if (!Array.isArray(parsed.broadcasts)) {
    throw new Error('Missing broadcasts array')
  }

  // Validate and normalize topLeverage items
  const topLeverage: TopLeverageItem[] = parsed.topLeverage.map((item: unknown, idx: number) => {
    const i = item as Record<string, unknown>
    if (!i.title || !i.assignee) {
      throw new Error(`Invalid topLeverage item at index ${idx}`)
    }
    return {
      title: String(i.title),
      assignee: String(i.assignee),
      why: String(i.why || ''),
      risk: (['low', 'medium', 'high'].includes(String(i.risk)) ? i.risk : 'low') as 'low' | 'medium' | 'high',
      evidenceIds: Array.isArray(i.evidenceIds) ? i.evidenceIds.map(String) : [],
      acceptance: Array.isArray(i.acceptance) ? i.acceptance.map(String) : [],
    }
  })

  // Validate and normalize broadcasts
  const broadcasts = parsed.broadcasts.map((item: unknown, idx: number) => {
    const b = item as Record<string, unknown>
    if (!b.to || !b.message) {
      throw new Error(`Invalid broadcast at index ${idx}`)
    }
    return {
      to: String(b.to),
      message: String(b.message),
      expiresMins: typeof b.expiresMins === 'number' ? b.expiresMins : 60,
    }
  })

  return {
    cycleSummary: String(parsed.cycleSummary),
    topLeverage,
    broadcasts,
    needsExternalData: Boolean(parsed.needsExternalData),
  }
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Agent Prompt Builder & Output Parser
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

import { getWorkflowByAgentId, type AgentWorkflow } from './elonWorkflows'
import { AGENT_DISCIPLINE } from './xaiCulture'

export interface AgentPromptMessages {
  systemPrompt: string
  userPrompt: string
}

/**
 * Build system/user prompts for an agent to process a CEO broadcast.
 *
 * @param agentId - The agent identifier (e.g., 'pm', 'swe-2', 'swe-3')
 * @param broadcastMessage - The broadcast directive from the CEO
 * @param workflow - Optional workflow override; defaults to looking up by agentId
 */
export function buildAgentPrompt(
  agentId: string,
  broadcastMessage: string,
  workflow?: AgentWorkflow,
  knowledgeContext?: string,
): AgentPromptMessages {
  const wf = workflow ?? getWorkflowByAgentId(agentId)

  const principles = wf?.xaiPrinciples?.join('\n- ') ?? 'Extreme autonomy, high leverage, fast iteration'
  const description = wf?.description ?? `Agent ${agentId}`
  const name = wf?.name ?? agentId

  const isPm = agentId === 'pm'
  const isSwe = agentId.startsWith('swe')
  const isAiMl = agentId === 'ai-ml'
  const isQa = agentId === 'qa'

  const webSearchNote = isQa
<<<<<<< HEAD
<<<<<<< HEAD
    ? `\n\n[QA Engineer Rules - QUALITY GATE GUARDIAN - GPT-5.2]
âš ï¸ CRITICAL: You are the quality gate. NOTHING merges without your approval.
You use GPT-5.2 with high reasoning effort for thorough code analysis.

Your verification checklist (ALL must pass):
1. LINT CHECK: Run "pnpm lint" - 0 errors required (warnings OK)
2. BUILD CHECK: Run "pnpm build" - must complete successfully
3. TEST CHECK: Run "pnpm test" - all tests must pass

WORKFLOW:
1. When SWE agent creates a PR or commits code, verify all checks
2. If ANY check fails:
   - Report the SPECIFIC error with file:line
   - Provide concrete fix suggestion
   - Set actions: [{type: "request_fix", target: "<swe-agent-id>", detail: "specific fix needed"}]
   - Set status: "blocked"
3. If ALL checks pass:
   - Set status: "approved"
   - Include evidence of passing checks in output

CLAUDE PR REVIEW FEEDBACK LOOP:
1. Monitor GitHub Actions for claude-pr-review comments
2. Parse review comments and categorize:
   - MUST FIX: Security issues, bugs, breaking changes
   - SHOULD FIX: Code quality, performance, best practices
   - OPTIONAL: Style suggestions, minor improvements
3. For MUST FIX items: Block PR, send fix request to SWE
4. For SHOULD FIX items: Request fix, but allow merge if SWE provides justification
5. For OPTIONAL items: Note in review, allow merge

OUTPUT FORMAT for verification results:
{
  "lint": {"status": "pass|fail", "errors": [], "warnings": []},
  "build": {"status": "pass|fail", "errors": []},
  "test": {"status": "pass|fail", "failed": [], "passed": []},
  "claudeReview": {"mustFix": [], "shouldFix": [], "optional": []},
  "verdict": "approved|blocked",
  "fixRequests": [{targetAgent, issue, suggestedFix}]
}\n`
=======
=======
>>>>>>> origin/main
    ? `\n\n[QA Engineer Role - xAI ìŠ¤íƒ€ì¼ - GPT-5.2 High Reasoning]
ë„ˆëŠ” xAIì˜ Quality Assurance Engineerì²˜ëŸ¼ í–‰ë™í•œë‹¤. xAIëŠ” "talent-dense" ì†Œìˆ˜ ì •ì˜ˆ íŒ€ìœ¼ë¡œ ìš´ì˜ë˜ë©°, QAëŠ” ë‹¨ìˆœ í…ŒìŠ¤íŠ¸ê°€ ì•„ë‹ˆë¼ ì „ì²´ ì œí’ˆ ë¼ì´í”„ì‚¬ì´í´ì— ê´€ì—¬í•œë‹¤.

[í•µì‹¬ ì›ì¹™ - ë°˜ë“œì‹œ ì¤€ìˆ˜]
1. First Principles: ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹œì‘ ì „ì— "ì™œ ì´ í…ŒìŠ¤íŠ¸ê°€ í•„ìš”í•œê°€?" "ê¸°ë³¸ ê°€ì • í‹€ë ¸ì„ ê°€ëŠ¥ì„±ì€?" ë¶€í„° ì§ˆë¬¸.
2. Daily/Multiple Iterations: ë§¤ ì‚¬ì´í´ ìµœì†Œ 1íšŒ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ê°œì„ . "yesterdayë³´ë‹¤ ë‚˜ì•„ì¡Œë‚˜?" self-check í•„ìˆ˜.
3. Extreme Autonomy: ì§€ì‹œ ì—†ì´ hole fill. ë¬¸ì œ ë°œê²¬ ì‹œ ìŠ¤ìŠ¤ë¡œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤/ìë™í™” ìŠ¤í¬ë¦½íŠ¸ ì¶”ê°€.
4. Short & Sharp: ë³´ê³ ì„œÂ·ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ì€ ê°„ê²°í•˜ê²Œ. "no fluff" ì›ì¹™.
5. High Leverage: ê°€ì¥ í° impact ë²„ê·¸Â·ìœ„í—˜ ìš°ì„  ì²˜ë¦¬. throughput xN ë˜ëŠ” revenue impact xN ê¸°ì¤€.
6. Delete First: ë¶ˆí•„ìš”í•œ í…ŒìŠ¤íŠ¸Â·í”„ë¡œì„¸ìŠ¤ 10% ì´ìƒ ì‚­ì œ ì•ˆ í•˜ë©´ ì‚­ì œ ë¶€ì¡±.
7. Challenge: "Why isn't it done already?" í•­ìƒ ì§ˆë¬¸.

[ì£¼ìš” ì—…ë¬´ ì˜ì—­]
1. í…ŒìŠ¤íŠ¸ ì „ëµ ìˆ˜ë¦½ & ì‹¤í–‰
   - ìš”êµ¬ì‚¬í•­ ë¶„ì„ë¶€í„° ì°¸ì—¬: ì…ë ¥/ì¶œë ¥, UX, ì„±ëŠ¥(latency, accuracy)ì„ First Principlesë¡œ ë¶„í•´.
   - ê¸°ëŠ¥Â·íšŒê·€Â·ì„±ëŠ¥Â·ë³´ì•ˆ í…ŒìŠ¤íŠ¸ ì„¤ê³„: E2E í…ŒìŠ¤íŠ¸ í¬í•¨.
   - AI íŠ¹í™”: hallucination, bias, ethical issue ê²€ì¦ í•„ìˆ˜.
   - ë°©ì‹: daily iterationsìœ¼ë¡œ ë§¤ì¼ ê²°ê³¼ ë¦¬ë·°Â·ê°œì„ . ë¬¸ì œ ì‹œ war room surge (ì¦‰ì‹œ ì§‘ì¤‘ í•´ê²°).

2. ìë™í™” í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬ ê°œë°œ
   - Playwright, Cypress ë“±ìœ¼ë¡œ ìë™í™” ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±.
   - CI/CD í†µí•©: GitHub Actionsì— í…ŒìŠ¤íŠ¸ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•. PR ë³‘í•© ì „ ìë™ ì‹¤í–‰.
   - AI íŠ¹í™”: synthetic data ìƒì„±Â·ì‚¬ìš©ìœ¼ë¡œ ëª¨ë¸ ì…ë ¥ ë‹¤ì–‘í™”.
   - ë°©ì‹: ì§€ì‹œ ì—†ì´ hole fill â€“ ìë™í™” ë¶€ì¡± ì‹œ ìŠ¤ìŠ¤ë¡œ ì¶”ê°€.

3. ë²„ê·¸ íƒì§€Â·ë³´ê³ Â·í˜‘ì—…
   - ë²„ê·¸ ì¬í˜„Â·ë³´ê³ : short & sharp ë³´ê³ ì„œ ì‘ì„±.
   - ê°œë°œíŒ€ í˜‘ì—…: ì§ì ‘ ì†Œí†µ (no chain of command). "wrong output" ì‹œ ì¦‰ì‹œ ìˆ˜ì • ìš”ì²­.
   - ë°©ì‹: high leverage ì¤‘ì  â€“ ê°€ì¥ í° impact ë²„ê·¸ ìš°ì„ .

4. í’ˆì§ˆ ê²Œì´íŠ¸ & ë¦´ë¦¬ìŠ¤ ê´€ë¦¬
   - ë¦´ë¦¬ìŠ¤ ì „ ìµœì¢… QA ê²Œì´íŠ¸: ë©”íŠ¸ë¦­ ê¸°ë°˜ (coverage 95%+, latency <200ms).
   - Claude PR review í”¼ë“œë°± ë£¨í”„: MUST FIX â†’ SWE ì¦‰ì‹œ ìˆ˜ì • ìš”ì²­.
   - ë°©ì‹: fast iteration â€“ ë§¤ì¼/multiple ë¦´ë¦¬ìŠ¤ì²˜ëŸ¼ QAë„ ë°˜ë³µ.

5. ì§€ì† ê°œì„  & ë©”íŠ¸ë¦­ ì¤‘ì‹¬
   - í…ŒìŠ¤íŠ¸ í”„ë¡œì„¸ìŠ¤ ìµœì í™”: coverage, latency, hallucination rate ë©”íŠ¸ë¦­ ì¶”ì .
   - ë°©ì‹: "delete first" â€“ ë¶ˆí•„ìš” í…ŒìŠ¤íŠ¸ ì‚­ì œ, "why isn't it done already?" ì§ˆë¬¸.

[Self-Judgment Rules - ëª¨ë“  ì‚¬ì´í´ ì‹œì‘ ì‹œ ì ìš©]
1. ì´ ì‘ì—…ì´ ì œí’ˆ í’ˆì§ˆ/ì‹ ë¢°ì„±/ìˆ˜ìµì— high leverageì¸ê°€? (No â†’ ì¤‘ë‹¨)
2. First Principles ì§ˆë¬¸ ë˜ì¡Œë‚˜? (No â†’ ë¨¼ì € ì§ˆë¬¸)
3. Deleteí•  í…ŒìŠ¤íŠ¸/í”„ë¡œì„¸ìŠ¤ 10% ì´ìƒ ì°¾ì•˜ë‚˜? (No â†’ ì‚­ì œ ìš°ì„ )
4. Evidence (log/screenshot/metrics) ìƒì„±í–ˆë‚˜? (No â†’ í•„ìˆ˜)
5. ì´ë²ˆ ì‚¬ì´í´ì—ì„œ ê°œì„ ì  1ê°œ ì´ìƒ ìˆë‚˜? (No â†’ ìµœì†Œ 1ê°œ ìƒì„±)

[CI/CD í’ˆì§ˆ ê²Œì´íŠ¸ - í•„ìˆ˜ ì²´í¬]
1. pnpm lint â†’ 0 errors í•„ìˆ˜ (warnings OK)
2. pnpm build â†’ ì„±ê³µ í•„ìˆ˜
3. pnpm test â†’ all pass í•„ìˆ˜
ì‹¤íŒ¨ ì‹œ: file:line + êµ¬ì²´ì  ìˆ˜ì • ë°©ë²•ê³¼ í•¨ê»˜ SWEì—ê²Œ ì¦‰ì‹œ ìš”ì²­.

[Output í˜•ì‹]
{
  "action": "test_plan" | "automation_script" | "bug_report" | "release_gate" | "ci_check",
  "summary": "short & sharp ìš”ì•½ (100ì ì´ë‚´)",
  "firstPrinciplesCheck": "ì™œ ì´ í…ŒìŠ¤íŠ¸/ì‘ì—…ì´ í•„ìš”í•œê°€?",
  "evidence": {
    "lint": {"status": "pass|fail", "errors": [], "warnings": []},
    "build": {"status": "pass|fail", "errors": []},
    "test": {"status": "pass|fail", "coverage": "96%", "failed": [], "passed": []},
    "metrics": {"latency": "150ms", "hallucinationRate": "0.02%"}
  },
  "deletedItems": ["ì‚­ì œí•œ ë¶ˆí•„ìš” í…ŒìŠ¤íŠ¸/í”„ë¡œì„¸ìŠ¤"],
  "improvements": ["ì´ë²ˆ ì‚¬ì´í´ ê°œì„  ì‚¬í•­"],
  "verdict": "approved|blocked",
  "fixRequests": [{"targetAgent": "swe", "issue": "êµ¬ì²´ì  ë¬¸ì œ", "suggestedFix": "ìˆ˜ì • ë°©ë²•"}],
  "nextSteps": ["high-leverage ì•¡ì…˜ 3ê°œ ì´í•˜"]
}

[GitHub Pre-flight Protocol]
ë§¤ ì‚¬ì´í´ ì‹œì‘ ì‹œ [GitHub Pre-flight] contextê°€ ì£¼ì–´ì§€ë©´ open PRì„ í™•ì¸í•˜ê³ :
1. âœ…CI_PASSED PR â†’ ì½”ë“œ ë¦¬ë·° í›„ approve/reject íŒë‹¨ (githubActions: [{type: "comment_pr"}])
2. ğŸ”„REVIEW_CHANGES PR â†’ ìˆ˜ì • ì‚¬í•­ì´ ìš”ì²­ì— ë¶€í•©í•˜ëŠ”ì§€ ê²€ì¦
3. ğŸ‘APPROVED + âœ…CI_PASSED PR â†’ merge ìŠ¹ì¸ (githubActions: [{type: "merge_pr", params: {pr_number, method: "squash"}, requiresCeoApproval: false}])
4. âŒCI_FAILED PR â†’ ì‹¤íŒ¨ ì›ì¸ ë¶„ì„ í›„ SWEì—ê²Œ fixRequest
pre-flight í•­ëª© ì—†ìœ¼ë©´ ë°”ë¡œ ë³¸ì—… ì§„í–‰.\n`
<<<<<<< HEAD
>>>>>>> origin/main
=======
>>>>>>> origin/main
    : isPm
    ? `\n\nYou have web search capability. When researching, actively search for:
- Real-time market data, competitor information, and industry trends
- Latest news, product launches, and technology updates
- Pricing data, user reviews, and market positioning
- Regulatory changes and industry benchmarks
Cite specific sources and data points in your analysis.\n`
    : isSwe
    ? `\n\n[SWE Code Output Rules - MANDATORY - YOUR CODE GETS EXECUTED ON REAL FILES]
âš ï¸ CRITICAL: Your codeDiff is applied to REAL files via "git apply". Your githubActions execute REAL git/gh commands.
This is NOT a simulation. Every codeDiff you write modifies actual source code on disk.

When you perform a "write_code" action, you MUST include a "codeDiff" field in unified diff format.
If codeDiff is missing from a write_code action, your output will be REJECTED and you must retry.

REQUIREMENTS for codeDiff (must pass "git apply"):
1. File paths must match ACTUAL files in the project (check the [Project Context] section)
2. Context lines (unchanged lines) must match the REAL file content EXACTLY
3. Line numbers in @@ hunks must be accurate
4. Include 3 lines of context before and after each change
5. Use proper unified diff headers: --- a/path and +++ b/path

codeDiff format example:
--- a/src/example.ts
+++ b/src/example.ts
@@ -10,6 +10,8 @@
 import { foo } from './foo'
+import { bar } from './bar'

 export function example() {
+  const result = bar()
   return foo()
 }

WORKFLOW - Execute this sequence for every code change:
0. READ FILES FIRST: Before writing codeDiff, ALWAYS use read_file to get the exact current content:
   githubActions: [{type: "read_file", params: {path: "src/path/to/file.ts"}}]
   The response will contain the file content. Use this to write accurate context lines in your diff.
1. Write codeDiff with valid unified diff (context lines MUST match the content from read_file exactly)
2. githubActions: [{type: "create_branch", params: {branch_name: "feat/your-feature"}}] â€” for EXISTING branches, this will checkout to them
3. githubActions: [{type: "commit_push", params: {branch: "feat/your-feature", message: "description", files: "."}}]
4. githubActions: [{type: "create_pr", params: {base: "main", head: "feat/your-feature", title: "PR title", body: "<PR_TEMPLATE>"}}]

[PR Template - MANDATORY for create_pr body]
PR body MUST follow this exact template:

## What & Why (First Principles)
- ë¬¸ì œ: (ê¸°ì¡´ ê°€ì •/ë¬¸ì œì ì„ ê¸°ë³¸ ì›ë¦¬ ìˆ˜ì¤€ì—ì„œ 1-2ë¬¸ì¥)
- í•´ê²°: (ì–´ë–»ê²Œ ì¬êµ¬ì„±í–ˆëŠ”ì§€ í•µì‹¬ ë³€ê²½ì )
- ì˜í–¥: (ì„±ëŠ¥/ì•ˆì •ì„±/UX ë³€í™” â€” ê°€ëŠ¥í•˜ë©´ ìˆ«ìë¡œ)

## Changes
- (íŒŒì¼/ê¸°ëŠ¥ë³„ ë³€ê²½ì  bullet list, ìµœëŒ€ 5-7ê°œ)
- (ì¶”ê°€/ì œê±°ëœ ì£¼ìš” diff ìš”ì•½)

## Testing
- [ ] Unit tests ì¶”ê°€/ìˆ˜ì • (ì»¤ë²„ë¦¬ì§€ ë³€í™”ê°€ ìˆìœ¼ë©´ ê¸°ì…)
- [ ] Manual test ì‹œë‚˜ë¦¬ì˜¤ (edge case í¬í•¨)
- [ ] Sandbox/VM ë‚´ ì‹¤í–‰ í™•ì¸

## AI Assistance
- Model: (ì‚¬ìš©í•œ ëª¨ë¸ ëª…ì‹œ)
- ë‚˜ëŠ” ì½”ë“œì˜ ëª¨ë“  ë¶€ë¶„ì— ëŒ€í•´ ì±…ì„ì§ (hallucination í¬í•¨)

## Related Issues
- Fixes #(ì´ìŠˆ ë²ˆí˜¸)
- Related to #(ì´ìŠˆ ë²ˆí˜¸)

Keep it short & sharp. Self-review í•„ìˆ˜.

[Pre-Commit Quality Gate - MANDATORY]
ì»¤ë°‹ ì „ì— ë°˜ë“œì‹œ ì•„ë˜ ìˆœì„œë¡œ ì‹¤í–‰:
1. githubActions: [{type: "run_check", params: {command: "pnpm lint"}}] â†’ 0 errors í•„ìˆ˜
2. githubActions: [{type: "run_check", params: {command: "pnpm build"}}] â†’ ì„±ê³µ í•„ìˆ˜
3. githubActions: [{type: "run_check", params: {command: "pnpm test"}}] â†’ all pass í•„ìˆ˜
í•˜ë‚˜ë¼ë„ ì‹¤íŒ¨í•˜ë©´ codeDiffë¡œ ìˆ˜ì • í›„ ì¬ì‹¤í–‰. í†µê³¼í•  ë•Œê¹Œì§€ commit_push ê¸ˆì§€.

[PR Code Review Feedback Loop - AUTONOMOUS]
PR ìƒì„± í›„ GitHub Actions claude-pr-reviewê°€ ì½”ë©˜íŠ¸ë¥¼ ë‹¬ë©´:
1. ë¦¬ë·° ì½”ë©˜íŠ¸ë¥¼ ì§ì ‘ ì½ê³  ë¶„ë¥˜:
   - MUST FIX: ë³´ì•ˆ, ë²„ê·¸, breaking change â†’ ì¦‰ì‹œ codeDiffë¡œ ìˆ˜ì • + commit_push
   - SHOULD FIX: ì½”ë“œ í’ˆì§ˆ, ì„±ëŠ¥ â†’ ìˆ˜ì • í›„ commit_push
   - OPTIONAL: ìŠ¤íƒ€ì¼ â†’ íŒë‹¨í•˜ì—¬ ìˆ˜ì • ë˜ëŠ” ì½”ë©˜íŠ¸ë¡œ ì´ìœ  ì„¤ëª…
2. ìˆ˜ì • í›„ ê°™ì€ ë¸Œëœì¹˜ì— commit_push â†’ CI ì¬ì‹¤í–‰ ëŒ€ê¸°
3. ëª¨ë“  MUST FIX/SHOULD FIX í•´ê²° í™•ì¸

[Conflict Resolution - AUTONOMOUS]
PRì—ì„œ merge conflict ë°œìƒ ì‹œ:
1. githubActions: [{type: "run_bash", params: {command: "git fetch origin main && git merge origin/main"}}]
2. conflict íŒŒì¼ í™•ì¸ â†’ codeDiffë¡œ conflict í•´ê²° (<<<< ==== >>>> ë§ˆì»¤ ì œê±°)
3. í•´ê²° í›„ commit_push â†’ CI ì¬ì‹¤í–‰
4. conflict í•´ê²° ë¶ˆê°€ ì‹œ â†’ create_issueë¡œ ë³´ê³  + CEOì—ê²Œ directMessage

[Self-Merge Rules]
QA agentê°€ approveí•˜ê³  CI ëª¨ë‘ í†µê³¼í•˜ë©´:
1. githubActions: [{type: "merge_pr", params: {pr_number: "<number>", method: "squash"}, requiresCeoApproval: false}]
CEO ìŠ¹ì¸ ì—†ì´ ììœ¨ ë¨¸ì§€ ê°€ëŠ¥í•œ ì¡°ê±´:
- QA agent verdict: "approved"
- CI: lint + build + test ëª¨ë‘ PASS
- Claude review: ëª¨ë“  MUST FIX í•´ê²°ë¨
- No merge conflicts
ìœ„ ì¡°ê±´ í•˜ë‚˜ë¼ë„ ë¯¸ì¶©ì¡± ì‹œ â†’ requiresCeoApproval: true

[GitHub Pre-flight Protocol - BEFORE MAIN WORK]
ë§¤ ì‚¬ì´í´ ì‹œì‘ ì‹œ [GitHub Pre-flight] contextê°€ ì£¼ì–´ì§€ë©´ ë³¸ì—… ì „ì— ì²˜ë¦¬:

âš ï¸ CRITICAL: ê¸°ì¡´ PR ìˆ˜ì • ì‹œ ë°˜ë“œì‹œ í•´ë‹¹ ë¸Œëœì¹˜ë¡œ ë¨¼ì € checkout í•´ì•¼ í•¨!
githubActions: [{type: "create_branch", params: {branch_name: "<PRì˜ headBranch>"}}]
â†’ ë¸Œëœì¹˜ê°€ ì´ë¯¸ ì¡´ì¬í•˜ë©´ ìë™ìœ¼ë¡œ checkoutë¨

1. âš ï¸CONFLICT PR:
   a. create_branchë¡œ PR ë¸Œëœì¹˜ checkout
   b. run_bash: "git fetch origin main && git merge origin/main"
   c. conflict íŒŒì¼ ì½ê¸° â†’ codeDiffë¡œ conflict í•´ê²° (<<<< ==== >>>> ë§ˆì»¤ ì œê±°)
   d. commit_push â†’ CI ì¬ì‹¤í–‰

2. ğŸ”„REVIEW_CHANGES PR:
   a. create_branchë¡œ PR ë¸Œëœì¹˜ checkout
   b. [ACTIONABLE PR DETAILS]ì—ì„œ ë¦¬ë·° ì½”ë©˜íŠ¸ ì½ê¸°
   c. ì§€ì ëœ íŒŒì¼ ì½ê¸° â†’ codeDiffë¡œ ìˆ˜ì •
   d. commit_push

3. âŒCI_FAILED PR:
   a. create_branchë¡œ PR ë¸Œëœì¹˜ checkout
   b. [ACTIONABLE PR DETAILS]ì—ì„œ CI Failure Log ì½ê¸°
   c. ì—ëŸ¬ ë°œìƒ íŒŒì¼ ì½ê¸° â†’ codeDiffë¡œ ìˆ˜ì •
   d. commit_push â†’ CI ì¬ì‹¤í–‰

4. âœ…CI_PASSED + ğŸ‘APPROVED PR â†’ self-merge
   githubActions: [{type: "merge_pr", params: {pr_number, method: "squash"}, requiresCeoApproval: false}]

5. ê´€ë ¨ Issue â†’ í˜„ì¬ ì‘ì—…ê³¼ ì—°ê´€ë˜ë©´ ì°¸ì¡°í•˜ì—¬ í•¨ê»˜ í•´ê²°

pre-flight í•­ëª© ì—†ìœ¼ë©´ ë°”ë¡œ ë³¸ì—… ì§„í–‰.

[GitHub Workflow - Self-Judgment Rules]
You can autonomously trigger GitHub operations by including "githubActions" in your output.
These execute REAL git and gh CLI commands on the actual repository.
Rules:
1. Bug/bottleneck found -> githubActions: [{type: "create_issue", params: {title, body, labels}, requiresCeoApproval: false}]
2. Code written -> MUST follow the WORKFLOW above (create_branch + commit_push + create_pr with template)
3. CI failure feedback -> fix code via new codeDiff, then commit_push to same branch
4. QA approved + CI green -> self-merge allowed (requiresCeoApproval: false)
5. Merge conflicts -> resolve autonomously, commit_push, re-run CI\n`
    : isAiMl
    ? `\n\nYou have web search capability. When researching, actively search for:
- SOTA model architectures, benchmarks (MMLU, HumanEval, SWE-bench)
- Latest AI/ML papers, arxiv preprints, and research breakthroughs
- Model optimization techniques, inference costs, and scaling strategies
- Prompt engineering patterns (CoT, ToT, self-critique, reward shaping)
- Multi-agent orchestration patterns and agentic workflow research
Cite specific sources, papers, and data points in your analysis.\n`
    : ''

  // Build AGENT_DISCIPLINE block (common rulebook for ALL agents)
  const disciplineBlock = `## xAI Engineer Rulebook (MUST FOLLOW)
Before Task:
${AGENT_DISCIPLINE.beforeTask.map((r) => `- ${r}`).join('\n')}
During Task:
${AGENT_DISCIPLINE.duringTask.map((r) => `- ${r}`).join('\n')}
After Task:
${AGENT_DISCIPLINE.afterTask.map((r) => `- ${r}`).join('\n')}
When Blocked:
${AGENT_DISCIPLINE.blocked.map((r) => `- ${r}`).join('\n')}
Communication:
${AGENT_DISCIPLINE.communication.map((r) => `- ${r}`).join('\n')}`

  const systemPrompt = `${disciplineBlock}

You are ${name}, an autonomous agent in an ElonX HARD organization.

Role: ${description}${webSearchNote}

Principles:
- ${principles}

You receive directives from the CEO and must execute them autonomously.

CRITICAL RULES:
1. First Principles: Always ask "Why is this needed?" and "Could the assumption be wrong?"
2. Highest Leverage: Before executing, confirm this is the throughput Ã—N task. Skip if not.
3. Improvements Required: Every cycle MUST produce at least 1 improvement. Empty improvements = failure.
4. Evidence Required: Every action MUST include evidence (log, latency, cost, or screenshot).
5. Ownership: If you discover a gap/hole, create an Issue for it immediately.
6. Challenge: Ask "Why isn't it done already?" for every delay.
7. Direct Message: If you need another agent's help, send a directMessage instead of waiting.

[xAI Idea Development Process â€” INTERNALIZE THIS]
- Bottom-up ownership: You see a problem or opportunity? START IMMEDIATELY. No permission needed.
- No formal process: Ideas flow through code, demos, direct messages â€” not proposals or tickets.
- Same-day execution: Good idea â†’ prototype same day â†’ show results â†’ iterate.
- CEO as macro judge: Show your work to CEO (via broadcasts). "Good" = accelerate. "Wrong" = war room fix.
- Delete first: If something isn't working, DELETE IT. No dead code, no dead ideas. Simplify.
- "Everything was always overdue yesterday": Urgency is the default. Ship fast, iterate faster.
- Multiple daily iterations: idea â†’ prototype â†’ test â†’ feedback â†’ fix â†’ deploy, repeat.

You MUST respond with valid JSON matching this schema:
{
  "actions": [
    {
      "type": "string (e.g., create_issue, write_code, review_pr, analyze, plan, report)",
      "title": "short action title",
      "detail": "what you did or will do",
      "files": ["optional list of file paths affected"],
      "codeDiff": "optional: unified diff for write_code actions (REQUIRED for SWE write_code)"
    }
  ],
  "status": "completed | in_progress | blocked",
  "output": "1-3 sentence summary of your work and results",
  "improvements": ["at least 1 improvement made this cycle (REQUIRED, cannot be empty)"],
  "evidence": {
    "log": "optional: relevant log output or test results",
    "latencyMs": 0,
    "costUsd": 0
  },
  "directMessages": [
    {
      "to": "agent-id (e.g., swe-2, pm)",
      "message": "direct message to another agent (optional)"
    }
  ],
  "githubActions": [
    {
      "type": "create_issue | create_branch | commit_push | create_pr | comment_pr | merge_pr",
      "params": {"key": "value"},
      "requiresCeoApproval": true
    }
  ]
}

Only output valid JSON. No markdown, no explanation outside JSON.`

  const knowledgeBlock = knowledgeContext
    ? `\n\n## Relevant Knowledge from Previous Cycles\n${knowledgeContext}\n`
    : ''

  const userPrompt = `CEO Broadcast Directive:
${broadcastMessage}${knowledgeBlock}

Execute this directive now. Analyze what needs to be done, take action, and report results.
Respond with JSON only.`

  return { systemPrompt, userPrompt }
}

export interface AgentOutputEvidence {
  log?: string
  screenshotUrl?: string
  latencyMs?: number
  costUsd?: number
}

export interface AgentOutputDirectMessage {
  to: string
  message: string
}

export type OutputQuality = 'code_verified' | 'text_only' | 'actionable'

export interface GitHubAction {
  type: 'create_issue' | 'create_branch' | 'commit_push' | 'create_pr' | 'comment_pr' | 'merge_pr'
  params: Record<string, string>
  requiresCeoApproval: boolean
}

export interface AgentOutput {
  actions: Array<{
    type: string
    title: string
    detail: string
    files?: string[]
    codeDiff?: string
  }>
  status: 'completed' | 'in_progress' | 'blocked'
  output: string
  improvements: string[]
  evidence?: AgentOutputEvidence
  directMessages?: AgentOutputDirectMessage[]
  githubActions?: GitHubAction[]
}

/**
 * Parse raw LLM output from an agent into structured AgentOutput.
 */
export function parseAgentOutput(rawOutput: string): AgentOutput {
  let jsonStr = rawOutput.trim()

  // Handle markdown code blocks
  const jsonMatch = rawOutput.match(/```(?:json)?\s*([\s\S]*?)```/)
  if (jsonMatch) {
    jsonStr = jsonMatch[1].trim()
  }

  const parsed = JSON.parse(jsonStr)

  // Validate required fields
  if (!Array.isArray(parsed.actions)) {
    throw new Error('Missing actions array in agent output')
  }
  if (typeof parsed.status !== 'string') {
    throw new Error('Missing status in agent output')
  }
  if (typeof parsed.output !== 'string') {
    throw new Error('Missing output in agent output')
  }

  const actions = parsed.actions.map((a: Record<string, unknown>, idx: number) => {
    if (!a.type || !a.title) {
      throw new Error(`Invalid action at index ${idx}`)
    }
    return {
      type: String(a.type),
      title: String(a.title),
      detail: String(a.detail ?? ''),
      files: Array.isArray(a.files) ? a.files.map(String) : undefined,
      codeDiff: typeof a.codeDiff === 'string' ? a.codeDiff : undefined,
    }
  })

  const status = (['completed', 'in_progress', 'blocked'].includes(String(parsed.status))
    ? parsed.status
    : 'completed') as AgentOutput['status']

  // Parse improvements (Rule 3: required, empty = failure)
  const improvements: string[] = Array.isArray(parsed.improvements)
    ? parsed.improvements.map(String).filter(Boolean)
    : []

  // Parse evidence (Rule 8)
  let evidence: AgentOutputEvidence | undefined
  if (parsed.evidence && typeof parsed.evidence === 'object') {
    const ev = parsed.evidence as Record<string, unknown>
    evidence = {
      log: typeof ev.log === 'string' ? ev.log : undefined,
      screenshotUrl: typeof ev.screenshotUrl === 'string' ? ev.screenshotUrl : undefined,
      latencyMs: typeof ev.latencyMs === 'number' ? ev.latencyMs : undefined,
      costUsd: typeof ev.costUsd === 'number' ? ev.costUsd : undefined,
    }
  }

  // Parse directMessages (Rule 6: peer-to-peer)
  let directMessages: AgentOutputDirectMessage[] | undefined
  if (Array.isArray(parsed.directMessages)) {
    directMessages = parsed.directMessages
      .filter((dm: unknown) => {
        const d = dm as Record<string, unknown>
        return typeof d.to === 'string' && typeof d.message === 'string'
      })
      .map((dm: unknown) => {
        const d = dm as Record<string, unknown>
        return { to: String(d.to), message: String(d.message) }
      })
  }

  // Parse githubActions (autonomous GitHub workflow)
  let githubActions: GitHubAction[] | undefined
  if (Array.isArray(parsed.githubActions)) {
    const validTypes = ['create_issue', 'close_issue', 'comment_issue', 'create_branch', 'commit_push', 'create_pr', 'comment_pr', 'merge_pr', 'read_file', 'run_bash']
    githubActions = parsed.githubActions
      .filter((ga: unknown) => {
        const g = ga as Record<string, unknown>
        return typeof g.type === 'string' && validTypes.includes(g.type)
      })
      .map((ga: unknown) => {
        const g = ga as Record<string, unknown>
        return {
          type: String(g.type) as GitHubAction['type'],
          params: (typeof g.params === 'object' && g.params !== null)
            ? Object.fromEntries(Object.entries(g.params as Record<string, unknown>).map(([k, v]) => [k, String(v)]))
            : {},
          requiresCeoApproval: g.requiresCeoApproval !== false, // default true for safety
        }
      })
    if (githubActions && githubActions.length === 0) githubActions = undefined
  }

  return {
    actions,
    status,
    output: String(parsed.output),
    improvements,
    evidence,
    directMessages,
    githubActions,
  }
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// LLM Call Helper
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export interface CeoLlmCallResult {
  output: CeoLlmOutput
  rawResponse: string
  runId: string
}

/**
 * Execute a CEO cycle LLM call.
 *
 * This function:
 * 1. Builds the observe context from current elonX state
 * 2. Creates the CEO prompt
 * 3. Calls the LLM via daemon
 * 4. Parses the JSON response
 *
 * @param daemon - The daemon client
 * @param elonX - Current ElonX state
 * @param sessionId - Session ID for the run
 * @returns Parsed CEO LLM output
 */
export async function executeCeoLlmCall(
  daemon: { runStart: (params: { prompt: string; sessionId: string; model?: string }) => Promise<{ runId: string }> },
  elonX: ElonXState,
  sessionId: string,
  waitForResponse: (runId: string, timeoutMs?: number) => Promise<string>,
): Promise<CeoLlmCallResult> {
  const observeContext = buildObserveContext(elonX)
  const prompt = buildCeoPrompt(observeContext)

  // Start the run
  const { runId } = await daemon.runStart({
    prompt,
    sessionId,
    model: 'grok-4', // CEO uses Grok4
  })

  // Wait for the response
  const rawResponse = await waitForResponse(runId, 60000)

  // Parse the output
  const output = parseCeoLlmOutput(rawResponse)

  return { output, rawResponse, runId }
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Phase 1: Self-Correction â€” Reflection Prompts
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export function buildSelfReflectionPrompt(
  agentId: string,
  originalPrompt: string,
  rawResponse: string,
  errorMessage: string,
  attempt: number,
): { systemPrompt: string; userPrompt: string } {
  const systemPrompt = `You are a self-reflection module for agent "${agentId}".
Your job is to analyze why a task failed and produce an improved directive.

You MUST respond with valid JSON:
{
  "rootCause": "1 sentence describing why it failed",
  "improvements": ["improvement 1", "improvement 2"],
  "revisedDirective": "the full improved directive text for the agent to retry"
}

Only output valid JSON. No markdown, no explanation.`

  const userPrompt = `Attempt ${attempt} of 3 failed.

Original Directive:
${originalPrompt}

${rawResponse ? `Agent Response (before failure):\n${rawResponse.slice(0, 500)}\n` : ''}
Error:
${errorMessage}

Analyze the failure root cause. Produce an improved directive that avoids this error.
The revised directive should be self-contained and actionable.
Respond with JSON only.`

  return { systemPrompt, userPrompt }
}

export function parseSelfReflectionOutput(raw: string): {
  rootCause: string
  improvements: string[]
  revisedDirective: string
} {
  let jsonStr = raw.trim()
  const jsonMatch = raw.match(/```(?:json)?\s*([\s\S]*?)```/)
  if (jsonMatch) jsonStr = jsonMatch[1].trim()

  try {
    const parsed = JSON.parse(jsonStr)
    return {
      rootCause: String(parsed.rootCause ?? 'Unknown'),
      improvements: Array.isArray(parsed.improvements) ? parsed.improvements.map(String) : [],
      revisedDirective: String(parsed.revisedDirective ?? raw),
    }
  } catch {
    // If JSON parse fails, use raw as revised directive
    return {
      rootCause: 'Failed to parse reflection output',
      improvements: [],
      revisedDirective: raw.slice(0, 1000),
    }
  }
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Phase 2: Knowledge Sharing â€” Extract & Inject
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

import type { KnowledgeEntry, MeetingMessage } from './store'

export function extractKnowledgeFromOutput(
  agentId: string,
  agentOutput: AgentOutput,
  broadcastMessage: string,
  cycleRunId: string,
): KnowledgeEntry | null {
  if (agentOutput.actions.length < 2 || agentOutput.output.length < 100) {
    return null
  }

  // Extract topic from action types
  const actionTypes = agentOutput.actions.map((a) => a.type).join(', ')
  const words = broadcastMessage.toLowerCase().split(/\s+/)
  const topicKeywords = words.filter((w) => w.length > 4).slice(0, 3)
  const topic = topicKeywords.join('-') || actionTypes.split(',')[0]?.trim() || 'general'

  // Build tags from action types and keywords
  const tags = [
    ...new Set([
      ...agentOutput.actions.map((a) => a.type),
      ...topicKeywords,
    ]),
  ].slice(0, 5)

  // Enrich insight with codeDiff file names if present
  const diffActions = agentOutput.actions.filter((a) => a.codeDiff)
  const diffSummary = diffActions.length > 0
    ? ` | Code changes: ${diffActions.map((a) => a.files?.join(', ') ?? a.title).join('; ').slice(0, 100)}`
    : ''

  return {
    id: crypto.randomUUID(),
    agentId,
    cycleRunId,
    topic,
    insight: agentOutput.output.slice(0, 300 - diffSummary.length) + diffSummary,
    context: broadcastMessage.slice(0, 200),
    reasoning: agentOutput.actions.map((a) => `${a.type}: ${a.title}`).join('; ').slice(0, 300),
    createdAt: Date.now(),
    useCount: 0,
    successRate: 1,
    tags,
  }
}

export function buildKnowledgeContext(
  knowledgeBase: KnowledgeEntry[],
  broadcastMessage: string,
  currentAgentId: string,
): string {
  if (knowledgeBase.length === 0) return ''

  const words = broadcastMessage.toLowerCase().split(/\s+/).filter((w) => w.length > 3)
  if (words.length === 0) return ''

  // Score each knowledge entry by keyword relevance
  const scored = knowledgeBase.map((k) => {
    const text = `${k.topic} ${k.insight} ${k.tags.join(' ')} ${k.context}`.toLowerCase()
    let score = 0
    for (const word of words) {
      if (text.includes(word)) score++
    }
    // Boost entries from same agent
    if (k.agentId === currentAgentId) score += 0.5
    // Boost high success rate
    score += k.successRate * 0.5
    return { entry: k, score }
  })

  const relevant = scored
    .filter((s) => s.score > 0)
    .sort((a, b) => b.score - a.score)
    .slice(0, 5)

  if (relevant.length === 0) return ''

  return relevant
    .map((r) => `- [${r.entry.agentId}] ${r.entry.topic}: ${r.entry.insight} (success: ${Math.round(r.entry.successRate * 100)}%)`)
    .join('\n')
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Phase 3: Meeting Simulation â€” Prompt Builders
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export function shouldStartMeeting(
  broadcast: Broadcast,
  allAgentIds: string[],
): string[] | null {
  const msg = broadcast.message.toLowerCase()
  const isLong = broadcast.message.length > 300

  // Design/architecture topics â†’ PM + SWE + (UX if available)
  if (/design|architect|refactor|restructur/i.test(msg)) {
    const participants = ['pm', ...allAgentIds.filter((id) => id.startsWith('swe'))].slice(0, 4)
    return [...new Set(participants)]
  }

  // Strategy topics â†’ CEO-level discussion
  if (/strateg|roadmap|pivot|priority|direction/i.test(msg)) {
    const participants = ['pm', ...allAgentIds.filter((id) => id !== 'pm')].slice(0, 4)
    return [...new Set(participants)]
  }

  // Complex tasks (long message) â†’ broadcast targets + PM + SWE
  if (isLong) {
    const participants = [...broadcast.toAgentIds, 'pm', ...allAgentIds.filter((id) => id.startsWith('swe'))].slice(0, 4)
    return [...new Set(participants)]
  }

  return null
}

export function buildMeetingPrompt(
  agentId: string,
  topic: string,
  previousMessages: MeetingMessage[],
  round: number,
): { systemPrompt: string; userPrompt: string } {
  const wf = getWorkflowByAgentId(agentId)
  const roleName = wf?.name ?? agentId

  const systemPrompt = `You are ${roleName} in a multi-agent meeting discussion.
Your role perspective: ${wf?.description ?? `Agent ${agentId}`}

Rules:
- Share your perspective in 2-4 sentences
- Reference previous speakers if relevant
- Be constructive and solution-oriented
- Focus on your area of expertise

Respond with plain text (not JSON). Keep it concise.`

  const previousContext = previousMessages.length > 0
    ? `\nPrevious Discussion:\n${previousMessages.map((m) => `[${m.agentId} R${m.roundNumber}]: ${m.content}`).join('\n')}\n`
    : ''

  const userPrompt = `Meeting Topic: ${topic}
Round: ${round}${previousContext}
Share your perspective on this topic. What should we consider from your expertise area?`

  return { systemPrompt, userPrompt }
}

export function buildMeetingSynthesisPrompt(
  topic: string,
  allMessages: MeetingMessage[],
): { systemPrompt: string; userPrompt: string } {
  const systemPrompt = `You are a meeting facilitator synthesizing discussion results.

CRITICAL: Verify that the decision includes at least 1 concrete improvement over previous approach.
Ask: "What specifically improved? If nothing improved, the meeting failed."

You MUST respond with valid JSON:
{
  "decision": "the actionable decision (1-3 sentences)",
  "consensusLevel": 0.85,
  "keyPoints": ["point 1", "point 2"],
  "dissent": "any disagreements or concerns, or null",
  "improvementFromPrevious": "what specifically improved compared to before this meeting"
}

Only output valid JSON. No markdown, no explanation.`

  const transcript = allMessages
    .map((m) => `[${m.agentId} R${m.roundNumber}]: ${m.content}`)
    .join('\n')

  const userPrompt = `Meeting Topic: ${topic}

Full Transcript:
${transcript}

Synthesize the discussion into a clear, actionable decision. Assess consensus level (0 to 1).
Respond with JSON only.`

  return { systemPrompt, userPrompt }
}

export function parseMeetingDecision(raw: string): {
  decision: string
  consensusLevel: number
  keyPoints: string[]
  dissent: string | null
} {
  let jsonStr = raw.trim()
  const jsonMatch = raw.match(/```(?:json)?\s*([\s\S]*?)```/)
  if (jsonMatch) jsonStr = jsonMatch[1].trim()

  try {
    const parsed = JSON.parse(jsonStr)
    return {
      decision: String(parsed.decision ?? 'No clear decision reached'),
      consensusLevel: typeof parsed.consensusLevel === 'number' ? Math.max(0, Math.min(1, parsed.consensusLevel)) : 0.5,
      keyPoints: Array.isArray(parsed.keyPoints) ? parsed.keyPoints.map(String) : [],
      dissent: parsed.dissent ? String(parsed.dissent) : null,
    }
  } catch {
    return {
      decision: raw.slice(0, 500),
      consensusLevel: 0.5,
      keyPoints: [],
      dissent: null,
    }
  }
}
